{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_selection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPxY5amH5ZbHDeCwe9VFiNZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcosmedvescig/thesis_survival_models_for_predicting_churn/blob/master/model_selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blHywm49oZCq",
        "colab_type": "text"
      },
      "source": [
        "# Model selection\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgP_pcggqiRh",
        "colab_type": "text"
      },
      "source": [
        "## Install libraries\n",
        "\n",
        "Note: After installing the libraries for the first time restart the notebook for the new versions of the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoeQZjHFqjz9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726
        },
        "outputId": "c921ed92-7bdb-4716-b8ca-105f393a32da"
      },
      "source": [
        "## Install libraries\n",
        "!pip install pysurvival=='0.1.2'\n",
        "!pip install scikit-survival=='0.13.1'\n",
        "!pip install osqp=='0.5.0'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pysurvival==0.1.2 in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: progressbar in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (2.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (1.5.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (0.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (1.18.5)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (0.14.1)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (from pysurvival==0.1.2) (19.3.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->pysurvival==0.1.2) (0.16.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival==0.1.2) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival==0.1.2) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival==0.1.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->pysurvival==0.1.2) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pysurvival==0.1.2) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pysurvival==0.1.2) (0.16.0)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow->pysurvival==0.1.2) (1.12.0)\n",
            "Requirement already satisfied: scikit-survival==0.13.1 in /usr/local/lib/python3.6/dist-packages (0.13.1)\n",
            "Requirement already satisfied: pandas>=0.21 in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn<0.24,>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy!=1.3.0,>=1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (1.4.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (2.7.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (0.16.0)\n",
            "Requirement already satisfied: cvxpy>=1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (1.0.31)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (1.2.5)\n",
            "Requirement already satisfied: osqp!=0.6.0,!=0.6.1 in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (0.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-survival==0.13.1) (1.18.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->scikit-survival==0.13.1) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21->scikit-survival==0.13.1) (2018.9)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival==0.13.1) (2.1.2)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival==0.13.1) (0.70.10)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy>=1.0->scikit-survival==0.13.1) (2.0.7.post1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp!=0.6.0,!=0.6.1->scikit-survival==0.13.1) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.21->scikit-survival==0.13.1) (1.12.0)\n",
            "Requirement already satisfied: dill>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy>=1.0->scikit-survival==0.13.1) (0.3.2)\n",
            "Requirement already satisfied: osqp==0.5.0 in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from osqp==0.5.0) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp==0.5.0) (0.16.0)\n",
            "Requirement already satisfied: scipy>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from osqp==0.5.0) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqx2w18jqdBV",
        "colab_type": "text"
      },
      "source": [
        "## Custom Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-ABryu0qf1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pysurvival.utils.metrics import concordance_index\n",
        "from pysurvival.utils.display import integrated_brier_score\n",
        "from sksurv.metrics import cumulative_dynamic_auc\n",
        "\n",
        "def evaluate_model(model,X_train,T_train, E_train,X_test,T_test,E_test,\n",
        "                   c_index=True,ibs=True,c_auc=True):\n",
        "\n",
        "    # c-index\n",
        "    if c_index:\n",
        "        from pysurvival.utils.metrics import concordance_index\n",
        "        c_index = concordance_index(model, X_test, T_test, E_test)\n",
        "        print('c-index: {0:5.4f}'.format(c_index))\n",
        "    else:\n",
        "        c_index=0\n",
        "\n",
        "    # ibs\n",
        "    if ibs:        \n",
        "        from pysurvival.utils.display import integrated_brier_score\n",
        "        ibs = integrated_brier_score(model, X_test, T_test, E_test, t_max=200,\n",
        "                    figure_size=(20, 6.5) )\n",
        "        print('IBS: {0:5.4f}'.format(ibs))\n",
        "    else:\n",
        "        ibs=1\n",
        "\n",
        "    # cumulative_auc\n",
        "    if c_auc:\n",
        "        from sksurv.metrics import cumulative_dynamic_auc\n",
        "\n",
        "        train = np.array([(e,t) for e,t in zip(E_train,T_train)],dtype=[('event', 'bool_'),('time','int_')])\n",
        "        test = np.array([(e,t) for e,t in zip(E_test,T_test)],dtype=[('event', 'bool_'),('time','int_')])\n",
        "\n",
        "        # auc does not support inf risk so we replace with a really large value\n",
        "        risk = model.predict_risk(X_test)\n",
        "        risk = np.where(risk == np.inf,100,risk)\n",
        "\n",
        "        auc_time_list,mean_auc = cumulative_dynamic_auc(train, test, risk, [100,150,300,500], tied_tol=1e-08)\n",
        "        print('AUC: {0:5.4f}'.format(mean_auc))\n",
        "    else:\n",
        "        mean_auc=0\n",
        "\n",
        "    #return results\n",
        "    results = pd.DataFrame({'c_index':[c_index],\n",
        "                                'ibs':[ibs],\n",
        "                                'mean_auc':[mean_auc]})\n",
        "    return results"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC0SChUjohr3",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4oJBu3WoPTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Open dataset\n",
        "raw_data = pd.read_csv('https://github.com/marcosmedvescig/thesis_survival_models_for_predicting_churn/raw/master/churn_data_anonymized_20200718.csv')\n",
        "raw_data.rename(columns={'survival_days': 'time', 'status': 'event'},inplace=True)\n",
        "\n",
        "raw_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0T-XvclppqNT",
        "colab_type": "text"
      },
      "source": [
        "## Create Train, Test and Eval datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1iOIr7opc7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Remove observations according to EDA\n",
        "\n",
        "raw_data = raw_data[raw_data['time']>=0]\n",
        "raw_data = raw_data[raw_data['products_created'] <= (raw_data['products_created'].mean() + 3 * raw_data['products_created'].std())]\n",
        "raw_data = raw_data[raw_data['admin_visits'] <= (raw_data['admin_visits'].mean() + 3 * raw_data['admin_visits'].std())]\n",
        "raw_data = raw_data[raw_data['tx'] <= (raw_data['tx'].mean() + 3 * raw_data['tx'].std())]\n",
        "raw_data = raw_data[raw_data['gmv_usd'] <= (raw_data['gmv_usd'].mean() + 3 * raw_data['gmv_usd'].std())]\n",
        "\n",
        "raw_data.reset_index(drop=True,inplace=True)\n",
        "\n",
        "# Defining the features\n",
        "\n",
        "X = pd.get_dummies(raw_data.drop(['store_id','time', 'event'], axis=1))\n",
        "T = raw_data['time']\n",
        "E = raw_data['event']\n",
        "\n",
        "## Create evaluation set, 70% of the raw_data.\n",
        "index_train_test, index_eval = train_test_split( range(len(raw_data)), test_size = 0.7, random_state = 2020)\n",
        "\n",
        "# Creating the X, T and E input\n",
        "X_train_test = X.loc[index_train_test].reset_index( drop = True )\n",
        "X_eval  = X.loc[index_eval].reset_index( drop = True )\n",
        "\n",
        "T_train_test = T.loc[index_train_test].reset_index( drop = True )\n",
        "T_eval  = T.loc[index_eval].reset_index( drop = True )\n",
        "\n",
        "E_train_test = E.loc[index_train_test].reset_index( drop = True )\n",
        "E_eval  = E.loc[index_eval].reset_index( drop = True )\n",
        "\n",
        "\n",
        "## Create train and test set, 30% of the raw_data.\n",
        "index_train, index_test = train_test_split( range(len(X_train_test)), test_size = 0.25, random_state = 2020)\n",
        "\n",
        "# Creating the X, T and E input\n",
        "X_train = X_train_test.loc[index_train].reset_index( drop = True )\n",
        "X_test  = X_train_test.loc[index_test].reset_index( drop = True )\n",
        "\n",
        "T_train = T_train_test.loc[index_train].reset_index( drop = True )\n",
        "T_test  = T_train_test.loc[index_test].reset_index( drop = True )\n",
        "\n",
        "E_train = E_train_test.loc[index_train].reset_index( drop = True )\n",
        "E_test  = E_train_test.loc[index_test].reset_index( drop = True )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0moQ3r2toGP",
        "colab_type": "text"
      },
      "source": [
        "## Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqTKuEA3t22E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "# Create empty dataframe for storing the results\n",
        "\n",
        "results = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o504VakAtp3i",
        "colab_type": "text"
      },
      "source": [
        "### Standard CoxPH model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwWoJiO1tq2n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.semi_parametric import CoxPHModel\n",
        "import pandas as pd\n",
        "\n",
        "# Creating an instance of the Cox PH model and fitting the data.\n",
        "\n",
        "## Build the model\n",
        "coxph = CoxPHModel()\n",
        "coxph.fit(X_train, T_train, E_train, lr=0.5, l2_reg=1e-2, init_method='zeros')\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(coxph,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['coxph']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5BJnCsnuB-G",
        "colab_type": "text"
      },
      "source": [
        "### DeepSurv/Non-Linear CoxPH model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qukpMSb6uCej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.semi_parametric import NonLinearCoxPHModel\n",
        "import pandas as pd\n",
        "\n",
        "# Creating an instance of the NonLinear CoxPH model and fitting the data.\n",
        "\n",
        "### Defining the MLP structure. Here we will build a 1-hidden layer \n",
        "### with 150 units and `BentIdentity` as its activation function\n",
        "structure = [ {'activation': 'BentIdentity', 'num_units': 150},  ]\n",
        "\n",
        "## Build the model\n",
        "nonlinear_coxph = NonLinearCoxPHModel(structure=structure)\n",
        "nonlinear_coxph.fit(X_train, T_train, E_train, lr=1e-3, init_method='xav_uniform')\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(nonlinear_coxph,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['nonlinear_coxph']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Kxfv8jJuNwH",
        "colab_type": "text"
      },
      "source": [
        "### Linear MTLR model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elHlVy2QuRdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.multi_task import LinearMultiTaskModel\n",
        "import pandas as pd\n",
        "\n",
        "# Creating an instance of the Linear MTLR model and fitting the data.\n",
        "\n",
        "## Build the model\n",
        "l_mtlr = LinearMultiTaskModel(bins=50)\n",
        "l_mtlr.fit(X_train, T_train, E_train, lr=0.00001, l2_reg=0.001, init_method='orthogonal')\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(l_mtlr,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['l_mtlr']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHeYmKrGuZ1S",
        "colab_type": "text"
      },
      "source": [
        "### Neural MTLR model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITTfCnRruaM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.multi_task import NeuralMultiTaskModel\n",
        "import pandas as pd\n",
        "\n",
        "#### 4 - Creating an instance of the Neural MTLR model and fitting the data.\n",
        "\n",
        "# Defining the MLP structure. Here we will build a 1-hidden layer \n",
        "# with 150 units and `Swish` as its activation function\n",
        "structure = [ {'activation': 'ReLU', 'num_units': 150},  ]\n",
        "\n",
        "# Building the model\n",
        "n_mtlr = NeuralMultiTaskModel(structure=structure, bins=150)\n",
        "n_mtlr.fit(X_train, T_train, E_train, \n",
        "            lr=0.00001, l2_reg=0.001, num_epochs = 500,\n",
        "           init_method='orthogonal', optimizer = 'sgd')\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(n_mtlr,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['n_mtlr']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBsNU5lnuhtj",
        "colab_type": "text"
      },
      "source": [
        "### Parametric Weibull Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z4kYSa2uh_u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.parametric import WeibullModel\n",
        "import pandas as pd\n",
        "\n",
        "# Creating an instance of the weibertz model and fitting the data.\n",
        "\n",
        "## Build the model\n",
        "weib = WeibullModel()\n",
        "weib.fit(X_train, T_train, E_train, lr=0.0001, init_method='zeros',\n",
        "    optimizer ='adam', l2_reg = 0.001, num_epochs=2000)\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(weib,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['weib']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyCtOfP3wEYk",
        "colab_type": "text"
      },
      "source": [
        "### Random Survival Forest model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYztYdgCwDx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.survival_forest import RandomSurvivalForestModel\n",
        "import pandas as pd\n",
        "\n",
        "## Build the model\n",
        "rsf = RandomSurvivalForestModel(num_trees=50)\n",
        "rsf.fit(X_train, T_train, E_train,\n",
        "        max_features=\"sqrt\", max_depth=5, min_node_size=20)\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(rsf,X_train,T_train,E_train,X_test,T_test,E_test)\n",
        "tmp_results['model'] = ['rsf']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iU94t4_wOIi",
        "colab_type": "text"
      },
      "source": [
        "### Linear SVM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR3YYCjewPQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pysurvival.models.svm import LinearSVMModel\n",
        "import pandas as pd\n",
        "\n",
        "# Creating an instance of the Linear SVM model and fitting the data.\n",
        "## Build Model\n",
        "svm_l = LinearSVMModel()\n",
        "svm_l.fit(X_train, T_train, E_train, init_method='he_uniform',\n",
        "    with_bias = True, lr = 0.5,  tol = 1e-3,  l2_reg = 1e-3)\n",
        "\n",
        "## Evaluate model\n",
        "tmp_results = evaluate_model(svm_l,X_train,T_train,E_train,X_test,T_test,E_test,ibs=False)\n",
        "tmp_results['model'] = ['svm_l']\n",
        "results = pd.concat([results, tmp_results], ignore_index=True)\n",
        "results.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUcrvWmcwa5u",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeRzBFMdweG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show results table\n",
        "\n",
        "results.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK89wUd4MLF7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('max c_index is on line:{}'.format(results['c_index'].idxmax()))\n",
        "print('max mean_auc is on line:{}'.format(results['mean_auc'].idxmax()))\n",
        "print('min ibs is on line:{}'.format(results['ibs'].idxmin()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}